# Leveraging Large Language Models for Developing Well-being Indicators  
**By Mohamed Sabbah**  

Today, social media platforms are more popular than ever, with around 5.24 billion people using them worldwide. This accounts for around 63.9% of the total global population[59]. One of the biggest social media platforms X (previously known as Twitter) has around 500 million posts sent each day. These tweets are considered unstructured data, which need to be processed before any useful information can be extracted from them. Given the vast volume of data points, these tweets qualify as big data. Instead of only counting on questionnaires and interviews to gather information about the public, the massive amount of social media posts and comments on different platforms can be used as a valuable source of information. This can also lead to fixing the problem of incentivization when it comes to public surveys. As mentioned before, the massive amount of unstructured data available online can be processed to obtain all kinds of information about the public. One of the uses is to analyze social mood and well-being at a given time period. This can allow for the introduction of policies and initiatives that would help the public, while being much quicker at addressing the problem as data can be obtained in real time. As a result, this thesis will utilize said unstructured data in order to create a subjective well-being indicator based on the mental health of the public. Different deep learning methods will be used to classify Italian tweets during the first six months of 2020, and then a defined well-being indicator will be used to see how it fluctuates during that time period. The indicator will be developed using a unique multi-label classification problem. There are four classes for the indicator, which are Normal, Anxious, Depressed, and Suicidal. Three different models will be compared when it comes to the classification tasks. The first model will be an attention-based Bidirectional Long Short-Term Memory model, with the other two models being Large Language Models. The first one will be the Bidirectional Encoder Representations from Transformers model (BERT), and the second one will be a much larger one, specifically Meta‚Äôs Llama3.2 3B. Both pre-trained models will be fine-tuned on the mental health dataset, with the only difference being the utilization of QLoRA for the Llama model due to its size. The comparison between the three models will be done by monitoring the accuracy, F1, recall, and precision scores. The models will process Italian tweets and classify them based on contents of the text. Each model will produce a classification result, and these results will be analyzed as a time series for comparison.

This repository contains the code and analysis for developing subjective well-being indicators using Large Language Models (LLMs) and deep learning techniques. 

## üìÇ Contents  
- **üìù [Data Preprocessing](https://github.com/masabbah-97/Data-Science-Portfolio/blob/main/Thesis/Data%20Pre-processing.ipynb)** ‚Äì This notebook contains all the pre-processing steps that is shared by the three models.
### ü§ñ Models
- **[Attention Based BiLSTM Model Training & Evaluation](https://github.com/masabbah-97/Data-Science-Portfolio/blob/main/Thesis/AttnBiLSTM.ipynb)** ‚Äì This notebook includes the pre-processing steps specific for the BiLSTM model, along with the model training steps and the evaluation of its performance.
- **[BERT Model Training & Evaluation](https://github.com/masabbah-97/Data-Science-Portfolio/blob/main/Thesis/AttnBiLSTM.ipynb)** ‚Äì This notebook includes the pre-processing steps specific for the BERT model, along with the model training steps and the evaluation of its performance.
- Fine-tuning BERT, Llama, and AB-BiLSTM for mental health classification.  
- **üìä Analysis & Results** ‚Äì Performance comparisons, word clouds, and trend visualizations.  
- **üîç Key Findings** ‚Äì Insights into model generalization and biases in well-being prediction.  
