{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention-based BiLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first model tested is an attention based BiLSTM. This model will act as a benchmark used to compare the results of the LLMs to. Furthermore, the reasoning behind choosing this type of model specifically is that BiLSTMs do not suffer from the vanishing gradients problems like RNNs. Evidently, utilizing the attention mechanism in this model should further boost its perfmance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo_SkW55nle2",
        "outputId": "47a29f3f-b4a5-446b-dbca-1d1fbcf643bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313472 sha256=5f02b72055b872031ca7dd7c4892c22a1848643d1e045bf1d71b9334f02c6cc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "!pip install keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9Cct9UZnbIz"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import F1Score\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import fasttext\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.optimizers import SGD, AdamW, RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are further pre-processing steps required for this model to perform well. The first one is to keep only alphaneumeric characters, while also removing stopwords. Links were also removed from the dataset for this model as it is not able to recognize them for what they are. Finally, the train, validation, and test datasets are tokenized and stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eU-1fSbngem",
        "outputId": "c924b2fa-81e9-4454-98de-44f67b58c9f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def tweet_to_words(tweet):\n",
        "    \"\"\"Convert tweet text into a sequence of words while keeping punctuation.\"\"\"\n",
        "    text = tweet.lower()\n",
        "    # Modify regex to keep specific punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z0-9 ]\", \" \", text)  # Notice the space inside the brackets\n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in stopwords.words(\"italian\")]\n",
        "    words = [PorterStemmer().stem(w) for w in words]\n",
        "    return words\n",
        "\n",
        "\n",
        "def remove_links_from_tweets(tweet):\n",
        "    \"\"\"Remove URLs from tweets.\"\"\"\n",
        "    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n",
        "    return re.sub(url_pattern, \"\", tweet)\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "#train_set = pd.read_csv('/content/drive/MyDrive/Thesis/Data/train_alt.csv')\n",
        "train_set = pd.read_csv('/content/drive/MyDrive/Italian thesis/Training dataset/train.csv')\n",
        "train_set=train_set.dropna()\n",
        "\n",
        "y_train = train_set['label']\n",
        "train_set.drop('label', axis=1, inplace=True)\n",
        "\n",
        "#val_set = pd.read_csv('/content/drive/MyDrive/Thesis/Data/val_alt.csv')\n",
        "val_set = pd.read_csv('/content/drive/MyDrive/Italian thesis/Training dataset/val.csv')\n",
        "y_val = val_set['label']\n",
        "val_set.drop('label', axis=1, inplace=True)\n",
        "\n",
        "#test_set = pd.read_csv('/content/drive/MyDrive/Thesis/Data/test_alt.csv')\n",
        "test_set = pd.read_csv('/content/drive/MyDrive/Italian thesis/Training dataset/test.csv')\n",
        "y_test = test_set['label']\n",
        "test_set.drop('label', axis=1, inplace=True)\n",
        "\n",
        "# Preprocess tweets\n",
        "for dataset in [train_set, val_set, test_set]:\n",
        "    dataset['italian text'] = dataset['italian text'].apply(remove_links_from_tweets)\n",
        "    dataset['italian text'] = dataset['italian text'].apply(tweet_to_words)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_words = 5000\n",
        "max_len = 50\n",
        "\n",
        "def tokenize_pad_sequences(text, tokenizer=None, fit=True):\n",
        "    if fit:\n",
        "        tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
        "        tokenizer.fit_on_texts(text)\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    padded = pad_sequences(sequences, padding=\"post\", maxlen=max_len)\n",
        "\n",
        "    return padded, tokenizer\n",
        "\n",
        "# Fit tokenizer on training data\n",
        "X_train, tokenizer = tokenize_pad_sequences(train_set['italian text'], fit=True)\n",
        "X_val, _ = tokenize_pad_sequences(val_set['italian text'], tokenizer, fit=False)\n",
        "X_test, _ = tokenize_pad_sequences(test_set['italian text'], tokenizer, fit=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The word embeddings used for this model are from a fastText model pre-trained on an italian corpus. They have a dimensions of 300, were trained using CBOW, with n-gram of lengths 5, have a window size of 5 and 10 negatives. They were trained using Common Crawl and Wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNsDL1DunjNW",
        "outputId": "ed67ca10-aa36-4526-a61e-68843dd87740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading FastText model...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the FastText model\n",
        "print(\"Loading FastText model...\")\n",
        "ft = fasttext.load_model('/content/drive/MyDrive/Italian thesis/cc.it.300.bin')\n",
        "\n",
        "# Save tokenizer for future use\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Create embedding matrix\n",
        "embedding_size = 300  # FastText vectors have 300 dimensions\n",
        "embedding_matrix = np.zeros((max_words, embedding_size))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_matrix[i] = ft.get_word_vector(word)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, the first thing done is defining the attention mechanism. Then, the model itself is defined. The final architecture has a word embeddings layer that can be finetuned, one Bidirectional LSTM layers, and two dense layers. Multiple model hyperparameters are finetuned before the final ones are chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-asLHzJnnZv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, return_sequences=True):\n",
        "        super(Attention, self).__init__()\n",
        "        self.return_sequences = return_sequences\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"att_weight\",\n",
        "                                 shape=(input_shape[-1], 1),\n",
        "                                 initializer=\"normal\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        self.b = self.add_weight(name=\"att_bias\",\n",
        "                                 shape=(input_shape[1], 1),\n",
        "                                 initializer=\"zeros\",\n",
        "                                 trainable=True)\n",
        "\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        e = tf.nn.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
        "        attention_weights = tf.nn.softmax(e, axis=1)\n",
        "\n",
        "        output = inputs * attention_weights\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "        else:\n",
        "            return tf.reduce_sum(output, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfWQ5ohEu9wd"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgrJVYEfs39U",
        "outputId": "6852d886-60ef-4f6e-c979-cb4368a6ac1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 30 Complete [00h 00m 17s]\n",
            "val_accuracy: 0.7387754917144775\n",
            "\n",
            "Best val_accuracy So Far: 0.7612245082855225\n",
            "Total elapsed time: 00h 08m 13s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Early Stopping Callback\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "nn_f1 = F1Score(name='f1_score', average='macro')\n",
        "\n",
        "class MyHyperModel(kt.HyperModel):\n",
        "    def __init__(self, max_words, embedding_size, embedding_matrix, max_len):\n",
        "        self.max_words = max_words\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=self.max_words,\n",
        "                            output_dim=self.embedding_size,\n",
        "                            weights=[self.embedding_matrix],\n",
        "                            input_length=self.max_len,\n",
        "                            trainable=True))\n",
        "\n",
        "        model.add(Bidirectional(LSTM(hp.Int(\"units_lstm_1\", min_value=32, max_value=128, step=32), return_sequences=True)))\n",
        "        #model.add(Bidirectional(LSTM(hp.Int(\"units_lstm_2\", min_value=16, max_value=64, step=16), return_sequences=True)))\n",
        "\n",
        "        model.add(Attention(return_sequences=False))  # Attention layer\n",
        "\n",
        "        model.add(Dense(hp.Int(\"dense_units\", min_value=128, max_value=512, step=64), activation=\"relu\"))  # Tunable Dense layer\n",
        "        model.add(Dropout(hp.Float(\"dropout\", min_value=0.3, max_value=0.6, step=0.1)))\n",
        "        model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "        # Select optimizer dynamically\n",
        "        optimizer_choice = hp.Choice(\"optimizer\", [\"SGD\", \"AdamW\", \"RMSprop\"])\n",
        "        learning_rate = hp.Float(\"learning_rate\", min_value=0.0001, max_value=0.1, sampling=\"log\")\n",
        "        weight_decay = hp.Float(\"weight_decay\", min_value=1e-6, max_value=1e-3, sampling=\"log\")\n",
        "\n",
        "        if optimizer_choice == \"SGD\":\n",
        "            momentum = hp.Float(\"momentum\", min_value=0.7, max_value=0.9, step=0.1)\n",
        "            optimizer = SGD(learning_rate=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
        "        elif optimizer_choice == \"AdamW\":\n",
        "            beta_1 = hp.Float(\"beta_1\", min_value=0.85, max_value=0.99, step=0.05)\n",
        "            beta_2 = hp.Float(\"beta_2\", min_value=0.95, max_value=0.999, step=0.05)\n",
        "            optimizer = AdamW(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2, weight_decay=weight_decay)\n",
        "        elif optimizer_choice == \"RMSprop\":\n",
        "            rho = hp.Float(\"rho\", min_value=0.8, max_value=0.99, step=0.05)\n",
        "            optimizer = RMSprop(learning_rate=learning_rate, rho=rho, decay=weight_decay)\n",
        "\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", nn_f1])\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [32, 64, 128]),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "# Initialize KerasTuner\n",
        "tuner = kt.Hyperband(\n",
        "    MyHyperModel(max_words, embedding_size, embedding_matrix, max_len),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory=\"my_tuner_dir\",\n",
        "    project_name=\"lstm_tuning\",\n",
        ")\n",
        "\n",
        "# Run the search\n",
        "tuner.search(X_train, y_train,\n",
        "             validation_data=(X_val, y_val),\n",
        "             epochs=10,\n",
        "             callbacks=[early_stopping])\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEbgp9qevU0p",
        "outputId": "90efa6f3-1d10-4631-a6e9-ede1fe7130ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters:\n",
            "  - Units (LSTM 1): 64\n",
            "  - Dropout: 0.4\n",
            "  - Optimizer: RMSprop\n",
            "  - Learning Rate: 0.005332108747674453\n",
            "  - Weight Decay: 1.2567208642033443e-05\n",
            "  - Units(Dense): 192\n",
            "  - Batch Size:32\n",
            "  - Rho: 0.9\n"
          ]
        }
      ],
      "source": [
        "print(f\"Best Hyperparameters:\\n\"\n",
        "      f\"  - Units (LSTM 1): {best_hps.get('units_lstm_1')}\\n\"\n",
        "      #f\"  - Units (LSTM 2): {best_hps.get('units_lstm_2')}\\n\"\n",
        "      f\"  - Dropout: {best_hps.get('dropout')}\\n\"\n",
        "      f\"  - Optimizer: {best_hps.get('optimizer')}\\n\"\n",
        "      f\"  - Learning Rate: {best_hps.get('learning_rate')}\\n\"\n",
        "      f\"  - Weight Decay: {best_hps.get('weight_decay')}\\n\"\n",
        "      f\"  - Units(Dense): {best_hps.get('dense_units')}\\n\"\n",
        "      f\"  - Batch Size:{best_hps.get('batch_size')}\")\n",
        "\n",
        "\n",
        "\n",
        "if best_hps.get(\"optimizer\") == \"SGD\":\n",
        "    print(f\"  - Momentum: {best_hps.get('momentum')}\")\n",
        "elif best_hps.get(\"optimizer\") == \"AdamW\":\n",
        "    print(f\"  - Beta 1: {best_hps.get('beta_1')}\")\n",
        "    print(f\"  - Beta 2: {best_hps.get('beta_2')}\")\n",
        "elif best_hps.get(\"optimizer\") == \"RMSprop\":\n",
        "    print(f\"  - Rho: {best_hps.get('rho')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU1NbriyZe-"
      },
      "source": [
        "### Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "KoKWowmVvxOi",
        "outputId": "c1d23531-b131-4127-dd8a-5e4710c2eb54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"AB-BiLSTM\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"AB-BiLSTM\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m1,500,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> (5.72 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,500,000\u001b[0m (5.72 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> (5.72 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,500,000\u001b[0m (5.72 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "nn_f1 = F1Score(name='f1_score', average='macro')\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "\n",
        "model = Sequential(name=\"AB-BiLSTM\")\n",
        "model.add(Embedding(input_dim=max_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_len,\n",
        "                    trainable=True))\n",
        "\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "model.add(Attention(return_sequences=False))  \n",
        "\n",
        "model.add(Dense(192, activation=\"relu\"))  \n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.005332108747674453, rho=0.9, decay=1.2567208642033443e-05)\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", nn_f1])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9fBKdzYyotK",
        "outputId": "e32edc69-b544-4eb5-890c-070f89e05eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5783 - f1_score: 0.4209 - loss: 0.9588 - val_accuracy: 0.7367 - val_f1_score: 0.4279 - val_loss: 0.6498\n",
            "Epoch 2/20\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7823 - f1_score: 0.4240 - loss: 0.5291 - val_accuracy: 0.7340 - val_f1_score: 0.4267 - val_loss: 0.6913\n",
            "Epoch 3/20\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8431 - f1_score: 0.4245 - loss: 0.4017 - val_accuracy: 0.7503 - val_f1_score: 0.4220 - val_loss: 0.6730\n",
            "Epoch 4/20\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8900 - f1_score: 0.4241 - loss: 0.2967 - val_accuracy: 0.7231 - val_f1_score: 0.4244 - val_loss: 0.8376\n",
            "Epoch 5/20\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9184 - f1_score: 0.4251 - loss: 0.2195 - val_accuracy: 0.7082 - val_f1_score: 0.4244 - val_loss: 1.0338\n",
            "Epoch 6/20\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9421 - f1_score: 0.4256 - loss: 0.1646 - val_accuracy: 0.7027 - val_f1_score: 0.4245 - val_loss: 1.4301\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[early_stopping],\n",
        "                    batch_size=32,\n",
        "                    epochs=20,\n",
        "                    verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "By looking at the metrics of the AB-BiLSTM model’s performance as shown by the performance metrics, it is evident that the model does not perform at a good enough level. The model has an overall accuracy and F1-score of 75%. The underlying numbers further explain this as it is evident the model has a hard time specifically when it comes to distinguishing between the ’Depression’ and ’Suicidal’ classes, with the class specific for both sitting at 63% and 71% respectively. This can be explained by some of the overlap between both mental health conditions, which can share multiple symptoms. This makes it understandably hard for the model to distinguish between the classes in some of the data points. The model performs much better on the ’Normal’ and the ’Anxiety’ classes as they are more ’obvious’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ck12-y3zkjo",
        "outputId": "a3bcc9ba-5e70-4416-e8fa-923606775344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Test Accuracy: 0.7517006993293762\n",
            "Test Precision: 0.7524316916295322\n",
            "Test Recall: 0.7595370370370371\n",
            "Test F1 Score: 0.7534062985888131\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "test_loss, test_acc, test_f1 = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "y_pred = model.predict(X_test, batch_size=64)\n",
        "\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "\n",
        "test_precision = precision_score(y_test, y_pred_classes, average='macro')\n",
        "test_recall = recall_score(y_test, y_pred_classes, average='macro')\n",
        "test_f1_scor = f1_score(y_test, y_pred_classes, average='macro')\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "print(f\"Test Precision: {test_precision}\")\n",
        "print(f\"Test Recall: {test_recall}\")\n",
        "print(f\"Test F1 Score: {test_f1_scor}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksc6N37iLBzq",
        "outputId": "b6028730-61ab-49e6-c797-f198344ac0e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Depression       0.68      0.55      0.60       400\n",
            "      Normal       0.86      0.91      0.88       400\n",
            "     Anxiety       0.80      0.85      0.83       270\n",
            "    Suicidal       0.67      0.74      0.70       400\n",
            "\n",
            "    accuracy                           0.75      1470\n",
            "   macro avg       0.75      0.76      0.75      1470\n",
            "weighted avg       0.75      0.75      0.75      1470\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test, y_pred_classes, target_names=['Depression', 'Normal', 'Anxiety', 'Suicidal'])\n",
        "\n",
        "# Print the report\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTb4TWcTlyT4",
        "outputId": "7caae4e5-0c35-4d64-d739-f863994ea28c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "            Depression  Normal  Anxiety  Suicidal\n",
            "Depression         218      26       38       118\n",
            "Normal               5     363       13        19\n",
            "Anxiety             22      10      229         9\n",
            "Suicidal            76      24        5       295\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "id2label = {0: 'Depression', 1: 'Normal', 2: 'Anxiety', 3: 'Suicidal'}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "cm_labels = np.array([id2label[i] for i in range(len(id2label))])\n",
        "cm_with_labels = pd.DataFrame(cm, index=cm_labels, columns=cm_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_with_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "CsPXLghFz1VN",
        "outputId": "94a7783c-e0a9-4bee-8ad2-dbad82fcfc08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"AB-BiLSTM\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"AB-BiLSTM\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,768</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">772</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │       \u001b[38;5;34m1,500,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m186,880\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention_1 (\u001b[38;5;33mAttention\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m178\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │          \u001b[38;5;34m24,768\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m772\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,425,198</span> (13.07 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,425,198\u001b[0m (13.07 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,712,598</span> (6.53 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,712,598\u001b[0m (6.53 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,712,600</span> (6.53 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,712,600\u001b[0m (6.53 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p42p6jHPug0S"
      },
      "source": [
        "## Indicator Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to build the indicator, the model will be used to classify a different set of tweets. These tweets are sampled (3000 for each day) from a dataset that contains 15 million tweets from the first 5 months of 2020. The same pre-processing steps are applied to this new dataset, these tweets are then using as input and the final predictions as well as the confidence values are then stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ps7sB4R0Kr-"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "data = pd.read_csv('/content/drive/MyDrive/Italian thesis/Training dataset/italian_with_predictions_large.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fTUK6QIulGt",
        "outputId": "de6d929f-5b96-487e-ae9a-3db512022e1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def tweet_to_words(tweet):\n",
        "    \"\"\"Convert tweet text into a sequence of words while keeping punctuation.\"\"\"\n",
        "    text = tweet.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.!?,;:()\\\"\\'-]\", \" \", text)  \n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in stopwords.words(\"italian\")]\n",
        "    words = [lemmatizer.lemmatize(w) for w in words] \n",
        "    return words\n",
        "\n",
        "\n",
        "def remove_links_from_tweets(tweet):\n",
        "    \"\"\"Remove URLs from tweets.\"\"\"\n",
        "    url_pattern = r\"https?://\\S+|www\\.\\S+\"\n",
        "    return re.sub(url_pattern, \"\", tweet)\n",
        "\n",
        "with open(\"tokenizer.pickle\", \"rb\") as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "def predict_sentiment(text, model, tokenizer):\n",
        "    text = remove_links_from_tweets(text) \n",
        "    words = tweet_to_words(text)  \n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences([words])\n",
        "    padded_sequence = pad_sequences(sequences, padding=\"post\", maxlen=max_len)\n",
        "\n",
        "    prediction = model.predict(padded_sequence, verbose=0)\n",
        "\n",
        "    predicted_label = np.argmax(prediction, axis=-1)[0]  \n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDQ5L6-LumKu",
        "outputId": "87593fb4-9bb4-49eb-ba06-489786633f5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 608000/608000 [12:33:25<00:00, 13.45it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data['lstm_prediction'] = data['testo'].progress_apply(lambda x: predict_sentiment(x, model, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKoBdJT2yBj5",
        "outputId": "aa2d2ea7-8fc4-4c10-9261-0948b8adcbb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions added to the DataFrame.\n"
          ]
        }
      ],
      "source": [
        "data.to_csv(\"/content/drive/MyDrive/Italian thesis/Training dataset/italian_with_predictions_large.csv\", index=False)\n",
        "\n",
        "print(\"Predictions added to the DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tLaaVWd19bcK",
        "outputId": "b8b07ed7-ba4b-4e6b-f00f-70eb18d9869e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7a87e1bb-dbfd-450d-97d5-6443dc7e6050\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>testo</th>\n",
              "      <th>tweet_date</th>\n",
              "      <th>llama_prediction</th>\n",
              "      <th>lstm_prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tollivincenzo avendo milioni a riserva era il ...</td>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt matteosalvinimi dati ufficiali istat econom...</td>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vado a letto con la consapevolezza che la mia ...</td>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>oggi alle finisce il mercato ma se ne apre un ...</td>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt danvmor ahahahah non è una sessione di merc...</td>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a87e1bb-dbfd-450d-97d5-6443dc7e6050')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a87e1bb-dbfd-450d-97d5-6443dc7e6050 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a87e1bb-dbfd-450d-97d5-6443dc7e6050');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4f2158e-c793-4c86-aece-898f09a73fe7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4f2158e-c793-4c86-aece-898f09a73fe7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4f2158e-c793-4c86-aece-898f09a73fe7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               testo  tweet_date  \\\n",
              "0  tollivincenzo avendo milioni a riserva era il ...  2020-01-31   \n",
              "1  rt matteosalvinimi dati ufficiali istat econom...  2020-01-31   \n",
              "2  vado a letto con la consapevolezza che la mia ...  2020-01-31   \n",
              "3  oggi alle finisce il mercato ma se ne apre un ...  2020-01-31   \n",
              "4  rt danvmor ahahahah non è una sessione di merc...  2020-01-31   \n",
              "\n",
              "   llama_prediction  lstm_prediction  \n",
              "0                 1                1  \n",
              "1                 1                3  \n",
              "2                 1                1  \n",
              "3                 1                1  \n",
              "4                 1                1  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T6NSgl_9gxw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cfWQ5ohEu9wd",
        "p42p6jHPug0S"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
